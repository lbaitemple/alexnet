{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0decbd7-88fe-4f4a-b749-b6eb6e8e8ccc",
   "metadata": {},
   "source": [
    "### Load two different AlexNet Models: \n",
    "\n",
    "i)  one model is alexnet (model)\n",
    "\n",
    "ii) another model is alexnetRT (model_trt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4069d24-638d-46c3-b979-04307e9c4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "from torch2trt import torch2trt\n",
    "from torchvision.models.alexnet import alexnet\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "\n",
    "model = models.alexnet(pretrained=True)\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba5010-9db1-4771-a16a-ae25988ae61f",
   "metadata": {},
   "source": [
    "### load alexnetRT m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ea4e2-2c9e-4aa7-b0a8-9ec9ce3642cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load TRT model\n",
    "modeltrt = TRTModule()\n",
    "modeltrt.load_state_dict(torch.load('alexnet_trt.pth'))\n",
    "device = torch.device('cuda')\n",
    "model_trt = modeltrt.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403fbc10-d59a-49f7-8c4e-2fa12db0a486",
   "metadata": {},
   "source": [
    "### Get imagenet classification names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba9bd03-f2dd-4e3f-9437-3418471bae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imagenet_classes.txt') as f:\n",
    "  labels = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779baba6-77a7-4330-93a4-55a982b21a01",
   "metadata": {},
   "source": [
    "### load image transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362e922-8430-4397-87b8-a8f290bdee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6308c227-02da-456c-ba4a-7f103949a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "from IPython.display import Image \n",
    "\n",
    "img = widgets.Image(format='jpeg', width=224, height=224)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a9d70-eee3-40e1-add2-e64aa7661899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, torch\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy\n",
    "\n",
    "file = open('turkish.jpg', \"rb\")\n",
    "img.value = file.read()\n",
    "imageStream = io.BytesIO(img.value)\n",
    "imageFile = Image.open(imageStream)\n",
    "imgarr = numpy.array(imageFile)\n",
    "\n",
    "input_image = PIL.Image.fromarray(imgarr)\n",
    "input_tensor=preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973db0ed-2431-4200-a78f-4905f7acbe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "output = model_trt(input_batch)\n",
    "index=torch.argmax(output)\n",
    "print(labels[index])\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be4015-0ed1-486c-a8e8-841b2bbfb8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "output = model(input_batch)\n",
    "index=torch.argmax(output)\n",
    "print(labels[index])\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335e95d-3db4-48df-94f2-3854e46929ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
